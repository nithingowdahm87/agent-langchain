from src.llm_clients.gemini_client import GeminiClient
from src.llm_clients.groq_client import GroqClient
from src.llm_clients.nvidia_client import NvidiaClient
from src.tools.file_ops import read_file, write_file
from src.utils.constants import GUIDELINES_K8S

class K8sWriterA:
    def __init__(self):
        self.llm = GeminiClient()
        
    def generate(self, context: str) -> str:
        try:
            system = read_file("configs/prompts/system_master.md")
            task = read_file("configs/prompts/k8s/writer_a.md")
        except Exception:
            system = "You are a K8s Engineer."
            task = "Generate Deployment manifests."
            
        prompt = f"{system}\n\n{task}\n\nAPPLICATION CONTEXT:\n{context}"
        return self.llm.call(prompt)

class K8sWriterB:
    def __init__(self):
        self.llm = GroqClient()
        
    def generate(self, context: str) -> str:
        try:
            system = read_file("configs/prompts/system_master.md")
            task = read_file("configs/prompts/k8s/writer_b.md")
        except Exception:
            system = "You are a Security Engineer."
            task = "Generate secure Deployment manifests."
            
        prompt = f"{system}\n\n{task}\n\nAPPLICATION CONTEXT:\n{context}"
        return self.llm.call(prompt)

class K8sWriterC:
    def __init__(self):
        self.llm = NvidiaClient()
        
    def generate(self, context: str) -> str:
        try:
            system = read_file("configs/prompts/system_master.md")
            task = read_file("configs/prompts/k8s/writer_c.md")
        except Exception:
            system = "You are an SRE."
            task = "Generate HA Deployment manifests."
            
        prompt = f"{system}\n\n{task}\n\nAPPLICATION CONTEXT:\n{context}"
        return self.llm.call(prompt)

class K8sReviewer:
    def __init__(self):
        from src.llm_clients.perplexity_client import PerplexityClient
        self.llm = PerplexityClient()
    
    def review_and_merge(self, yaml_a: str, yaml_b: str, yaml_c: str, validation_report: str = "") -> tuple[str, str]:
        """
        Uses Perplexity AI to intelligently review all 3 K8s manifests.
        """
        # Load guidelines
        try:
            guidelines = read_file(GUIDELINES_K8S)
        except Exception:
            guidelines = "No specific guidelines available."
        
        # Build comprehensive review prompt
        review_prompt = f"""
        You are an expert Kubernetes architect reviewing 3 different manifest sets generated by AI models.
        
        GUIDELINES TO FOLLOW:
        {guidelines}
        
        VALIDATION REPORT (Linter Errors to Fix):
        {validation_report}
        
        MANIFEST A (Production-focused):
        ```yaml
        {yaml_a}
        ```
        
        MANIFEST B (Security-focused):
        ```yaml
        {yaml_b}
        ```
        
        MANIFEST C (Performance-focused):
        ```yaml
        {yaml_c}
        ```
        
        YOUR TASK:
        1. Analyze all 3 manifest sets against the guidelines
        2. CRITICAL: Fix any errors mentioned in the VALIDATION REPORT.
        3. Identify strengths and weaknesses of each
        4. Select the best one OR combine the best elements from all three
        5. Explain WHY your choice is best with specific points
        
        OUTPUT FORMAT:
        First, provide 3-5 bullet points explaining why your selection is best.
        Then provide the final YAML manifests.
        
        Example:
        REASONING:
        - HPA configuration enables auto-scaling based on CPU/memory
        - Resource limits prevent resource exhaustion
        - Health probes ensure zero-downtime deployments
        - Pod Disruption Budget maintains availability during updates
        - Fixed kubeval error by adding missing selector
        
        YAML:
        apiVersion: apps/v1
        kind: Deployment
        ...
        
        Provide your response in this exact format.
        """.strip()
        
        # Get AI review
        try:
            response = self.llm.call(review_prompt)

            # Parse response
            if "YAML:" in response:
                parts = response.split("YAML:", 1)
                reasoning = parts[0].replace("REASONING:", "").strip()
                yaml_content = parts[1].strip()
            else:
                # Fallback if format not followed
                reasoning = "AI review completed"
                yaml_content = response

            # Clean up any markdown artifacts
            yaml_content = yaml_content.replace("```yaml", "").replace("```", "").strip()

            return (yaml_content + "\n", reasoning)

        except Exception as e:
            print(f"Warning: AI review failed ({e}), falling back to longest valid output")
            # Fallback to deterministic logic if AI fails
            candidates = []
            if "apiVersion" in yaml_a: candidates.append(yaml_a)
            if "apiVersion" in yaml_b: candidates.append(yaml_b)
            if "apiVersion" in yaml_c: candidates.append(yaml_c)
            if not candidates:
                return ("# No valid YAML generated.\n", "No valid outputs to review")
            best = max(candidates, key=len).strip() + "\n"
            return (best, "Fallback: Selected longest valid YAML")

class K8sExecutor:
    def run(self, final_yaml: str, output_path: str) -> None:
        write_file(output_path, final_yaml)
        print(f"Wrote {output_path}. Next manual step:")
        print(f"  kubectl apply -f {output_path}")
